{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26ed0df-8358-4311-979e-7dee59f931cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0507110-587b-4b81-a6a1-746cbcc04fcf",
   "metadata": {},
   "source": [
    "### 一、数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2239d63-b1ad-4b54-a26c-b5b73e282ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('../mydata/data_origin/220602_0902-cblue-nlp-医疗nlp打榜/CHIP-CDN/CHIP-CDN_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc04489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>左膝退变伴游离体</td>\n",
       "      <td>膝骨关节病##膝关节游离体</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>糖尿病反复低血糖;骨质疏松;高血压冠心病不稳定心绞痛</td>\n",
       "      <td>糖尿病性低血糖症##骨质疏松##高血压##冠状动脉粥样硬化性心脏病##不稳定性心绞痛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>右乳腺癌IV期</td>\n",
       "      <td>乳腺恶性肿瘤##癌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>头痛.头晕.高血压</td>\n",
       "      <td>头痛##头晕##高血压</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>骶裂半大便失控</td>\n",
       "      <td>骶椎椎板裂##大便失禁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text                           normalized_result\n",
       "0                    左膝退变伴游离体                               膝骨关节病##膝关节游离体\n",
       "1  糖尿病反复低血糖;骨质疏松;高血压冠心病不稳定心绞痛  糖尿病性低血糖症##骨质疏松##高血压##冠状动脉粥样硬化性心脏病##不稳定性心绞痛\n",
       "2                     右乳腺癌IV期                                   乳腺恶性肿瘤##癌\n",
       "3                   头痛.头晕.高血压                                 头痛##头晕##高血压\n",
       "4                     骶裂半大便失控                                 骶椎椎板裂##大便失禁"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c511823-f6b2-4952-94be-2d950cf3a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df = pd.read_excel('../mydata/data_origin/220602_0902-cblue-nlp-医疗nlp打榜/CHIP-CDN/国际疾病分类 ICD-10北京临床版v601.xlsx',\n",
    "                        header=None\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3a42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df.columns = 'code name'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d9c623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00</td>\n",
       "      <td>霍乱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00.0</td>\n",
       "      <td>霍乱,由于01群霍乱弧菌,霍乱生物型所致</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                  name\n",
       "0    A00                    霍乱\n",
       "1  A00.0  霍乱,由于01群霍乱弧菌,霍乱生物型所致"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b195ca79-34d3-4cd7-b4c0-0e49d561a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e151ee-4bb9-4470-8492-386aed4ea303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _text in icd_df['name']:\n",
    "    map_dict[_text].add(_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afa36e7-0636-48dc-b19d-fedada6df796",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _text in train_df['normalized_result']:\n",
    "    for _label in _text.split('##'):\n",
    "        map_dict[_label].add(_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567eccb7-7af3-4ad0-a955-73b5e247ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _text, _labels in zip(train_df['text'], train_df['normalized_result']):\n",
    "    for _label in _labels.split('##'):\n",
    "        map_dict[_text].add(_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d71be-e3b8-431b-89a7-7c35768ef0d3",
   "metadata": {},
   "source": [
    "### 二、召回模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65eb28e3-9076-40a1-a12b-43fd84d6af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from six import iteritems\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class BM25(object):\n",
    "    \"\"\"\n",
    "    BM25模型\n",
    "\n",
    "    Args:\n",
    "        corpus (:obj:`list`):\n",
    "            检索的语料\n",
    "        k1 (:obj:`float`, optional, defaults to 1.5):\n",
    "            取正值的调优参数，用于文档中的词项频率进行缩放控制\n",
    "        b (:obj:`float`, optional, defaults to 0.75):\n",
    "            0到1之间的参数，决定文档长度的缩放程度，b=1表示基于文档长度对词项权重进行完全的缩放，b=0表示归一化时不考虑文档长度因素\n",
    "        epsilon (:obj:`float`, optional, defaults to 0.25):\n",
    "            idf的下限值\n",
    "        tokenizer (:obj:`object`, optional, defaults to None):\n",
    "            分词器，用于对文档进行分词操作，默认为None，按字颗粒对文档进行分词\n",
    "        is_retain_docs (:obj:`bool`, optional, defaults to False):\n",
    "            是否保持原始文档\n",
    "\n",
    "    Reference:\n",
    "        [1] https://github.com/RaRe-Technologies/gensim/blob/3.8.3/gensim/summarization/bm25.py\n",
    "    \"\"\"  # noqa: ignore flake8\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        corpus,\n",
    "        k1=1.5,\n",
    "        b=0.75,\n",
    "        epsilon=0.25,\n",
    "        tokenizer=None,\n",
    "        is_retain_docs=False\n",
    "    ):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.docs = None\n",
    "        self.corpus_size = 0\n",
    "        self.avgdl = 0\n",
    "        self.doc_freqs = []\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "\n",
    "        if is_retain_docs:\n",
    "            self.docs = copy.deepcopy(corpus)\n",
    "\n",
    "        if tokenizer:\n",
    "            corpus = [self.tokenizer.tokenize(document) for document in corpus]\n",
    "        else:\n",
    "            corpus = [list(document) for document in corpus]\n",
    "\n",
    "        self._initialize(corpus)\n",
    "\n",
    "    def _initialize(self, corpus):\n",
    "        \"\"\"Calculates frequencies of terms in documents and in corpus. Also computes inverse document frequencies.\"\"\"\n",
    "        nd = {}  # word -> number of documents with word\n",
    "        num_doc = 0\n",
    "        for document in corpus:                        \n",
    "            self.corpus_size += 1\n",
    "            self.doc_len.append(len(document))\n",
    "            num_doc += len(document)\n",
    "\n",
    "            frequencies = {}\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.doc_freqs.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in nd:\n",
    "                    nd[word] = 0\n",
    "                nd[word] += 1\n",
    "\n",
    "        self.avgdl = float(num_doc) / self.corpus_size\n",
    "\n",
    "        idf_sum = 0\n",
    "        negative_idfs = []\n",
    "        for word, freq in iteritems(nd):\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = float(idf_sum) / len(self.idf)\n",
    "\n",
    "        if self.average_idf < 0:\n",
    "            logger.warning(\n",
    "                'Average inverse document frequency is less than zero. Your corpus of {} documents'\n",
    "                ' is either too small or it does not originate from natural text. BM25 may produce'\n",
    "                ' unintuitive results.'.format(self.corpus_size)\n",
    "            )\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_score(self, query, index):\n",
    "        score = 0.0\n",
    "        doc_freqs = self.doc_freqs[index]\n",
    "        numerator_constant = self.k1 + 1\n",
    "        denominator_constant = self.k1 * (1 - self.b + self.b * self.doc_len[index] / self.avgdl)\n",
    "        for word in query:\n",
    "            if word in doc_freqs:\n",
    "                df = self.doc_freqs[index][word]\n",
    "                idf = self.idf[word]\n",
    "                score += (idf * df * numerator_constant) / (df + denominator_constant)\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        scores = [self.get_score(query, index) for index in range(self.corpus_size)]\n",
    "        return scores\n",
    "\n",
    "    def recall(self, query, topk=5):\n",
    "        scores = self.get_scores(query)\n",
    "        indexs = np.argsort(scores)[::-1][:topk]\n",
    "\n",
    "        if self.docs is None:\n",
    "            return [[i, scores[i]] for i in indexs]\n",
    "        else:\n",
    "            return [[self.docs[i], scores[i]] for i in indexs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf8d662-1a25-405e-b14d-8c8857481199",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_model = BM25([_text for _text, _ in map_dict.items()], is_retain_docs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6810d2-f956-4127-a781-2bd703b14a83",
   "metadata": {},
   "source": [
    "### 三、召回率评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf74b6a-ce12-4e65-874e-9f10a0fa315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [02:28, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "召回率为：  0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_data_df = pd.read_json('../mydata/data_origin/220602_0902-cblue-nlp-医疗nlp打榜/CHIP-CDN/CHIP-CDN_dev.json')\n",
    "\n",
    "a_label = []\n",
    "new_train_data = []\n",
    "recall_ = 0 \n",
    "query_counter = 0\n",
    "miss_list = []\n",
    "\n",
    "for text_, normalized_result_ in tqdm(zip(dev_data_df['text'], dev_data_df['normalized_result'])):\n",
    "    query_counter += 1\n",
    "    \n",
    "    result = set([_result for _results in bm25_model.recall(text_, topk=200) for _result in map_dict[_results[0]]])\n",
    "            \n",
    "    if len(set(normalized_result_.split('##')) & result) != len(set(normalized_result_.split('##'))):\n",
    "        miss_list.append([text_, normalized_result_])\n",
    "        continue\n",
    "        \n",
    "    recall_ += 1\n",
    "    \n",
    "print('召回率为： ', recall_/query_counter)\n",
    "\n",
    "# 召回率为：  0.9135"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457df2e-b802-4d94-b4b3-fa353741af03",
   "metadata": {},
   "source": [
    "### 四、模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "466ec34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p checkpoint/recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebbf3485-df33-472a-9d80-a11db74018a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('checkpoint/recall/bm25_model.pkl', \"wb\") as f:\n",
    "    pickle.dump(bm25_model, f)\n",
    "    \n",
    "with open('checkpoint/recall/map_dict.pkl', \"wb\") as f:\n",
    "    pickle.dump(map_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388c8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
