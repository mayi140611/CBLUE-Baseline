{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from ark_nlp.model.tc.bert import Bert\n",
    "from ark_nlp.model.tc.bert import BertConfig\n",
    "from ark_nlp.model.tc.bert import Dataset\n",
    "from ark_nlp.model.tc.bert import Task\n",
    "from ark_nlp.model.tc.bert import get_default_model_optimizer\n",
    "from ark_nlp.model.tc.bert import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、数据读入与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.read_json('../mydata/data_origin/220602_0902-cblue-nlp-医疗nlp打榜/CHIP-CDN/CHIP-CDN_train.json')\n",
    "dev_data_df = pd.read_json('../mydata/data_origin/220602_0902-cblue-nlp-医疗nlp打榜/CHIP-CDN/CHIP-CDN_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['normalized_result_num'] = train_data_df['normalized_result'].apply(lambda x: len(x.split('##')))\n",
    "dev_data_df['normalized_result_num'] = dev_data_df['normalized_result'].apply(lambda x: len(x.split('##')))\n",
    "\n",
    "train_data_df['normalized_result_num_label'] = train_data_df['normalized_result_num'].apply(lambda x: 0 if x > 2 else x)\n",
    "dev_data_df['normalized_result_num_label'] = dev_data_df['normalized_result_num'].apply(lambda x: 0 if x > 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = (train_data_df\n",
    "                 .loc[:,['text', 'normalized_result_num_label']]\n",
    "                 .rename(columns={'normalized_result_num_label': 'label'}))\n",
    "\n",
    "dev_data_df = (dev_data_df\n",
    "               .loc[:,['text', 'normalized_result_num_label']]\n",
    "               .rename(columns={'normalized_result_num_label': 'label'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_train_dataset = Dataset(train_data_df)\n",
    "tc_dev_dataset = Dataset(dev_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 词典创建和生成分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab='nghuyong/ernie-1.0', max_seq_len=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ID化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_train_dataset.convert_to_ids(tokenizer)\n",
    "tc_dev_dataset.convert_to_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 二、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 模型参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('nghuyong/ernie-1.0',\n",
    "                                    num_labels=len(tc_train_dataset.cat2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nghuyong/ernie-1.0 were not used when initializing Bert: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing Bert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Bert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Bert were not initialized from the model checkpoint at nghuyong/ernie-1.0 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dl_module = Bert.from_pretrained('nghuyong/ernie-1.0', \n",
    "                                 config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 三、任务构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 任务参数和必要部件设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置运行次数\n",
    "num_epoches = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(dl_module.named_parameters())\n",
    "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 任务创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Thu Jun 16 06:20:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   72C    P0    72W /  70W |   9760MiB / 15109MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   70C    P0    65W /  70W |  11381MiB / 15109MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   70C    P0    62W /  70W |   8282MiB / 15109MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            Off  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   58C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Task(dl_module, 'adamw', 'lsce', cuda_device=3, ema_decay=0.995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      " 53% 100/188 [00:48<00:43,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/188],train loss is:0.888844,train evaluation is:0.589063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 188/188 [01:31<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[0],train loss is:0.831329,train evaluation is:0.636469 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73       277\n",
      "           1       0.76      0.79      0.77       972\n",
      "           2       0.63      0.64      0.63       751\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.73      0.69      0.71      2000\n",
      "weighted avg       0.72      0.71      0.71      2000\n",
      "\n",
      "confusion_matrix_: \n",
      " [[181   9  87]\n",
      " [  4 769 199]\n",
      " [ 36 237 478]]\n",
      "test loss is:0.730034,test acc is:0.714000,f1_score is:0.710654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 100/188 [00:49<00:44,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/188],train loss is:0.702268,train evaluation is:0.745313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 188/188 [01:33<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[1],train loss is:0.693873,train evaluation is:0.747008 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       277\n",
      "           1       0.78      0.83      0.80       972\n",
      "           2       0.68      0.65      0.66       751\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.75      0.74      0.74      2000\n",
      "weighted avg       0.75      0.75      0.75      2000\n",
      "\n",
      "confusion_matrix_: \n",
      " [[204   7  66]\n",
      " [  7 806 159]\n",
      " [ 46 219 486]]\n",
      "test loss is:0.697966,test acc is:0.748000,f1_score is:0.744426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 100/188 [00:50<00:44,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/188],train loss is:0.608291,train evaluation is:0.809063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 188/188 [01:34<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[2],train loss is:0.611963,train evaluation is:0.806682 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78       277\n",
      "           1       0.81      0.82      0.81       972\n",
      "           2       0.69      0.71      0.70       751\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.78      0.75      0.76      2000\n",
      "weighted avg       0.77      0.77      0.77      2000\n",
      "\n",
      "confusion_matrix_: \n",
      " [[202   6  69]\n",
      " [  6 794 172]\n",
      " [ 34 183 534]]\n",
      "test loss is:0.701244,test acc is:0.765000,f1_score is:0.763522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 100/188 [00:50<00:44,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/188],train loss is:0.532102,train evaluation is:0.866875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 188/188 [01:34<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[3],train loss is:0.540341,train evaluation is:0.861868 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.77       277\n",
      "           1       0.82      0.80      0.81       972\n",
      "           2       0.68      0.72      0.70       751\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.77      0.75      0.76      2000\n",
      "weighted avg       0.76      0.76      0.76      2000\n",
      "\n",
      "confusion_matrix_: \n",
      " [[204   6  67]\n",
      " [  5 776 191]\n",
      " [ 41 169 541]]\n",
      "test loss is:0.716088,test acc is:0.760500,f1_score is:0.759777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 100/188 [00:50<00:44,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/188],train loss is:0.479787,train evaluation is:0.896250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 188/188 [01:34<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[4],train loss is:0.489596,train evaluation is:0.892287 \n",
      "\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       277\n",
      "           1       0.83      0.80      0.81       972\n",
      "           2       0.68      0.73      0.70       751\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.78      0.76      0.76      2000\n",
      "weighted avg       0.77      0.77      0.77      2000\n",
      "\n",
      "confusion_matrix_: \n",
      " [[205   2  70]\n",
      " [  6 774 192]\n",
      " [ 38 162 551]]\n",
      "test loss is:0.744606,test acc is:0.765000,f1_score is:0.764847\n"
     ]
    }
   ],
   "source": [
    "model.fit(tc_train_dataset, \n",
    "          tc_dev_dataset,\n",
    "          lr=3e-5,\n",
    "          epochs=num_epoches, \n",
    "          batch_size=batch_size,\n",
    "          params=optimizer_grouped_parameters\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ema.store(model.module.parameters())\n",
    "model.ema.copy_to(model.module.parameters())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 四、模型验证与保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_nlp.factory.predictor import TCPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_predictor_instance = TCPredictor(model.module, tokenizer, tc_train_dataset.cat2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 0.7087128162384033)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_predictor_instance.predict_one_sample('怀孕伴精神障碍',\n",
    "                                         return_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p checkpoint/predict_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.module.state_dict(),\n",
    "           'checkpoint/predict_num/module.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('checkpoint/predict_num/cat2id.pkl', \"wb\") as f:\n",
    "    pickle.dump(tc_train_dataset.cat2id, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
